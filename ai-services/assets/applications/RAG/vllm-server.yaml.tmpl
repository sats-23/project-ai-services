apiVersion: v1
kind: Pod
metadata:
  name: "{{ .AppName }}--vllm-server"
  labels:
    ai-services.io/application: "{{ .AppName }}"
spec:
  containers:
    - name: embedding
      image: icr.io/ppc64le-oss/vllm-ppc64le:0.9.1
      command: ["/bin/sh", "-c"]
      args: [
          "vllm serve ibm-granite/granite-embedding-278m-multilingual --port 8001"
      ]
      livenessProbe:
        httpGet:
          path: /health
          port: 8001
        initialDelaySeconds: 600
        periodSeconds: 30
        timeoutSeconds: 5
        failureThreshold: 3
      resources:
        requests:
          memory: "10Gi"
        limits:
          memory: "10Gi"
      ports:
        - containerPort: 8001
    - name: reranker
      image: icr.io/ppc64le-oss/vllm-ppc64le:0.9.1
      command: ["/bin/sh", "-c"]
      args: [
          "vllm serve BAAI/bge-reranker-v2-m3 --port 8002"
      ]
      livenessProbe:
        httpGet:
          path: /health
          port: 8002
        initialDelaySeconds: 600
        periodSeconds: 30
        timeoutSeconds: 5
        failureThreshold: 3
      resources:
        requests:
          memory: "10Gi"
        limits:
          memory: "10Gi"
      ports:
        - containerPort: 8002
